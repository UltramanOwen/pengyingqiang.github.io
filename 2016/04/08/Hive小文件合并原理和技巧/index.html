<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?1f37d6e1c93f4addbd32c6f1b3266ade";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  
  <title>Hive小文件合并原理和技巧 | Box</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. 为什么做小文件合并hadoop的namenode负责hdfs文件系统所以目录和文件结构管理，小文件过多，会增加namenode的存储和计算压力，namenode不像datanode那样多个节点共同工作，小文件过多会占用namenode内存资源，当client读取或者写入大量小文件则有可能给namenode造成很大压力，最终影响整个集群稳定性
1.1 Map Reduce个数作业会通过inpu">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive小文件合并原理和技巧">
<meta property="og:url" content="http://pengyq.org/2016/04/08/Hive小文件合并原理和技巧/index.html">
<meta property="og:site_name" content="Box">
<meta property="og:description" content="1. 为什么做小文件合并hadoop的namenode负责hdfs文件系统所以目录和文件结构管理，小文件过多，会增加namenode的存储和计算压力，namenode不像datanode那样多个节点共同工作，小文件过多会占用namenode内存资源，当client读取或者写入大量小文件则有可能给namenode造成很大压力，最终影响整个集群稳定性
1.1 Map Reduce个数作业会通过inpu">
<meta property="og:updated_time" content="2016-04-08T10:57:23.659Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive小文件合并原理和技巧">
<meta name="twitter:description" content="1. 为什么做小文件合并hadoop的namenode负责hdfs文件系统所以目录和文件结构管理，小文件过多，会增加namenode的存储和计算压力，namenode不像datanode那样多个节点共同工作，小文件过多会占用namenode内存资源，当client读取或者写入大量小文件则有可能给namenode造成很大压力，最终影响整个集群稳定性
1.1 Map Reduce个数作业会通过inpu">
  
    <link rel="alternative" href="/atom.xml" title="Box" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/box.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Box</a></h1>
		</hgroup>

		
		<p class="header-subtitle">业精于勤荒于嬉，行成于思毁于随</p>
		

		
			<div class="switch-btn">
			
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0"> 
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
				</div>
			
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/随笔">随笔</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/pengyq" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/kerwinpeng" title="weibo">weibo</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/pengyq" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="mailto:peng.yq@qq.com" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/undefined/" style="font-size: 10px;"></a> <a href="/tags/javascript/" style="font-size: 10px;"> javascript</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/R/" style="font-size: 10px;">R</a> <a href="/tags/css/" style="font-size: 10px;">css</a> <a href="/tags/html/" style="font-size: 10px;">html</a> <a href="/tags/matplotlib/" style="font-size: 10px;">matplotlib</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/zeppelin/" style="font-size: 10px;">zeppelin</a> <a href="/tags/优化/" style="font-size: 10px;">优化</a> <a href="/tags/公式/" style="font-size: 10px;">公式</a> <a href="/tags/小文件/" style="font-size: 10px;">小文件</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/理论/" style="font-size: 10px;">理论</a> <a href="/tags/算法包/" style="font-size: 10px;">算法包</a> <a href="/tags/随笔/" style="font-size: 20px;">随笔</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">就职于腾讯。擅长数据分析，大数据平台架构，数据库，Java Web，Python，数据挖掘爱好者 …</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Box</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/box.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Box</h1>
			</hgroup>
			
			<p class="header-subtitle">业精于勤荒于嬉，行成于思毁于随</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/随笔">随笔</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/pengyq" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/kerwinpeng" title="weibo">weibo</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/pengyq" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="mailto:peng.yq@qq.com" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Hive小文件合并原理和技巧" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/04/08/Hive小文件合并原理和技巧/" class="article-date">
  	<time datetime="2016-04-08T09:57:00.000Z" itemprop="datePublished">2016-04-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hive小文件合并原理和技巧
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/优化/">优化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/小文件/">小文件</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/大数据/">大数据</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-__u4E3A_u4EC0_u4E48_u505A_u5C0F_u6587_u4EF6_u5408_u5E76"><a href="#1-__u4E3A_u4EC0_u4E48_u505A_u5C0F_u6587_u4EF6_u5408_u5E76" class="headerlink" title="1. 为什么做小文件合并"></a>1. 为什么做小文件合并</h2><p>hadoop的namenode负责hdfs文件系统所以目录和文件结构管理，小文件过多，会增加namenode的存储和计算压力，namenode不像datanode那样多个节点共同工作，小文件过多会占用namenode内存资源，当client读取或者写入大量小文件则有可能给namenode造成很大压力，最终影响整个集群稳定性</p>
<h4 id="1-1_Map_Reduce_u4E2A_u6570"><a href="#1-1_Map_Reduce_u4E2A_u6570" class="headerlink" title="1.1 Map Reduce个数"></a>1.1 Map Reduce个数</h4><p>作业会通过input的目录产生一个或者多个map任务。 主要的决定因素有： input的文件总个数，input的文件大小，集群设置的文件块大小(目前为128M, 可在hive中通过set dfs.block.size;命令查看到，该参数不能自定义修改)；</p>
<p>根据实际数据情况，集群设置 dfs.block.size=268435456    –(256M)</p>
<h4 id="1-2__u4E3E_u4F8B_uFF1A"><a href="#1-2__u4E3E_u4F8B_uFF1A" class="headerlink" title="1.2 举例："></a>1.2 举例：</h4><blockquote>
<p>（1）   假设input目录下有1个文件a,大小为780M,那么hadoop会将该文件a分隔成7个块（3个256m的块和1个12m的块），从而产生4个map数</p>
<p>（2）  假设input目录下有3个文件a,b,c,大小分别为10m，20m，300m，那么hadoop会分隔成4个块（10m,20m,256m,44m）,从而产生4个map数即，如果文件大于块大小(256m),那么会拆分，如果小于块大小，则把该文件当成一个块。</p>
</blockquote>
<h4 id="1-3__u662F_u4E0D_u662Fmap_u6570_u8D8A_u591A_u8D8A_u597D_uFF1F"><a href="#1-3__u662F_u4E0D_u662Fmap_u6570_u8D8A_u591A_u8D8A_u597D_uFF1F" class="headerlink" title="1.3 是不是map数越多越好？"></a>1.3 是不是map数越多越好？</h4><p>  答案是否定的。如果一个任务有很多小文件（远远小于块大小256m）,则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p>
<h4 id="1-4__u4FDD_u8BC1_u6BCF_u4E2Amap_u5904_u7406_u63A5_u8FD1256m_u7684_u6587_u4EF6_u5757_uFF0C_u5C31_u9AD8_u6795_u65E0_u5FE7_u4E86_uFF1F"><a href="#1-4__u4FDD_u8BC1_u6BCF_u4E2Amap_u5904_u7406_u63A5_u8FD1256m_u7684_u6587_u4EF6_u5757_uFF0C_u5C31_u9AD8_u6795_u65E0_u5FE7_u4E86_uFF1F" class="headerlink" title="1.4 保证每个map处理接近256m的文件块，就高枕无忧了？"></a>1.4 保证每个map处理接近256m的文件块，就高枕无忧了？</h4><p>答案也是不一定。比如有一个255m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。针对上面的问题3和4，我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<h4 id="1-5__u5982_u4F55_u51CF_u5C11map_u6570"><a href="#1-5__u5982_u4F55_u51CF_u5C11map_u6570" class="headerlink" title="1.5 如何减少map数"></a>1.5 如何减少map数</h4><p>减少map数可以通过合并小文件、调整文件块大小来完成<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">max</span>.<span class="keyword">split</span>.<span class="keyword">size</span>= <span class="number">268435456</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">min</span>.<span class="keyword">split</span>.<span class="keyword">size</span>.per.node=<span class="number">100000000</span>;</span> <span class="comment">--datanode上文件大于这个值才会合并</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">min</span>.<span class="keyword">split</span>.<span class="keyword">size</span>.per.rack=<span class="number">100000000</span>;</span><span class="comment">--多个机架上的数据是否需要合并</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">input</span>.<span class="keyword">format</span>=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-6__u5982_u4F55_u589E_u52A0map_u6570"><a href="#1-6__u5982_u4F55_u589E_u52A0map_u6570" class="headerlink" title="1.6 如何增加map数"></a>1.6 如何增加map数</h4><p>例如:<br>一个map文件只有250M 但是其中的记录数有上千万，而且SQL对每个记录操作非常复杂，那么需要增加map数来加快处理速度。</p>
<p>map数只能根据输入原始文件大小和个数来决定，那么需要在计算之前做数据处理<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> mapred.reduce.tasks=<span class="number">10</span>;</span>                  </span><br><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> a_1 <span class="keyword">as</span>                   </span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> a                   </span><br><span class="line"><span class="keyword">distribute</span> <span class="keyword">by</span> <span class="keyword">rand</span>(<span class="number">123</span>);</span></span><br></pre></td></tr></table></figure></p>
<p>变相SQL增加reduce来合并小文件<br>所以根据具体数据情况具体设置，合理利用计算资源。</p>
<p>PS:此处为什么用distribute by，具体可以了解Order by, Sort by ,Dristribute by,Cluster By的差异</p>
<h4 id="1-7__u63A7_u5236hive_u4EFB_u52A1_u7684reduce_u6570"><a href="#1-7__u63A7_u5236hive_u4EFB_u52A1_u7684reduce_u6570" class="headerlink" title="1.7 控制hive任务的reduce数"></a>1.7 控制hive任务的reduce数</h4><p>reduce个数的设定极大影响任务执行效率，不指定reduce个数的情况下，Hive会猜测确定一个reduce个数，基于以下两个设定</p>
<p>hive.exec.reducers.bytes.per.reducer（每个reduce任务处理的数据量，默认为1000^3=1G）<br>hive.exec.reducers.max（每个任务最大的reduce数，默认为999）计算reducer数的公式很简单N=min(参数2，总输入数据量/参数1)即，如果reduce的输入（map的输出）总大小不超过1G,那么只会有一个reduce任务；</p>
<blockquote>
<p>a) 调整reduce个数方法一： 调整hive.exec.reducers.bytes.per.reducer参数的值；set hive.exec.reducers.bytes.per.reducer=500000000; （500M）这次有20个reduce</p>
<p>b) 调整reduce个数方法二； set mapred.reduce.tasks = 15;这次有15个reduce</p>
</blockquote>
<h4 id="1-8__u4EC0_u4E48_u60C5_u51B5_u4E0B_u53EA_u6709_u4E00_u4E2Areduce"><a href="#1-8__u4EC0_u4E48_u60C5_u51B5_u4E0B_u53EA_u6709_u4E00_u4E2Areduce" class="headerlink" title="1.8 什么情况下只有一个reduce"></a>1.8 什么情况下只有一个reduce</h4><p>很多时候你会发现任务中不管数据量多大，不管你有没有设置调整reduce个数的参数，任务中一直都只有一个reduce任务；其实只有一个reduce任务的情况，除了数据量小于hive.exec.reducers.bytes.per.reducer参数值的情况外，还有以下原因：</p>
<blockquote>
<p>（1） 没有group by的汇总，比如把select pt,count(1) from tb group by pt; 写成 select count(1) from tb  这点非常常见，希望大家尽量改写。<br>（2） 用了Order by<br>（3） 有笛卡尔积     通常这些情况下，除了找办法来变通和避免，我暂时没有什么好的办法，因为这些操作都是全局的，所以hadoop不得不用一个reduce去完成；</p>
</blockquote>
<h2 id="2-_Hive_u5C0F_u6587_u4EF6_u5904_u7406_u8F93_u51FA_u63A7_u5236_u7BC7"><a href="#2-_Hive_u5C0F_u6587_u4EF6_u5904_u7406_u8F93_u51FA_u63A7_u5236_u7BC7" class="headerlink" title="2. Hive小文件处理输出控制篇"></a>2. Hive小文件处理输出控制篇</h2><p>Hive输出产生小文件的原主要分两种:</p>
<p><strong>a)  reduce个数过多且每个reduce输出结果较少<br>b)  或者map-only的查询，输入了很多小文件</strong></p>
<h4 id="2-1__u89E3_u51B3_u529E_u6CD5_3A"><a href="#2-1__u89E3_u51B3_u529E_u6CD5_3A" class="headerlink" title="2.1 解决办法:"></a>2.1 解决办法:</h4><p>（1） 减少reduce个数<br>（2） 增加reduce 控制输出文件格式<br>（3） 小文件合并设置[方法比较通用，无需修改业务SQL]</p>
<h4 id="2-2_hive_u5C0F_u6587_u4EF6_u5408_u5E76"><a href="#2-2_hive_u5C0F_u6587_u4EF6_u5408_u5E76" class="headerlink" title="2.2 hive小文件合并"></a>2.2 hive小文件合并</h4><p>控制输出的文件大小和个数除了reduce个数、map个数之外下面几个参数也比较关键。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">output</span>.compression.<span class="keyword">type</span>=<span class="keyword">BLOCK</span>;</span>默认是RECORD</span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.mapredfiles = <span class="literal">true</span>;</span>在Map-Reduce的任务结束时合并小文件默认false</span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.mapfiles = <span class="literal">true</span>;</span> 在Map-only的任务结束时合并小文件</span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.smallfiles.avgsize=<span class="number">160000000</span>;</span>默认16000000注意少了一个0</span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.exec.<span class="keyword">compress</span>.<span class="keyword">output</span>=<span class="literal">true</span>;</span>默认false输出结果压缩</span><br><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">output</span>.compression.codec= org.apache.hadoop.io.<span class="keyword">compress</span>.GzipCodec;</span>压缩格式</span><br></pre></td></tr></table></figure></p>
<h4 id="2-3__u9664_u6B64_u4E4B_u5916_u5BF9_u6587_u4EF6_u5B58_u50A8_u683C_u5F0F_u4E5F_u6709_u8981_u6C42"><a href="#2-3__u9664_u6B64_u4E4B_u5916_u5BF9_u6587_u4EF6_u5B58_u50A8_u683C_u5F0F_u4E5F_u6709_u8981_u6C42" class="headerlink" title="2.3 除此之外对文件存储格式也有要求"></a>2.3 除此之外对文件存储格式也有要求</h4><p>这里的文件格式可以设置textfile(默认)、sequencefile、rcfile</p>
<p>下面对这sequencefile和rcfile 文件格式结合GzipCodec、DefaultCodec做了测试对比。</p>
<p><strong>GzipCodec</strong>  </p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:left">CPU Time</th>
<th style="text-align:right">输出文件大小</th>
<th>输出文件数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">textfile</td>
<td style="text-align:left">2 days 4 hours 0 minutes 29 seconds 350 msec</td>
<td style="text-align:right">161G</td>
<td>4586</td>
</tr>
<tr>
<td style="text-align:center">sequencefile</td>
<td style="text-align:left">2 days 1 hours 9 minutes 52 seconds 560 msec</td>
<td style="text-align:right">181G</td>
<td>690</td>
</tr>
<tr>
<td style="text-align:center">rcfile</td>
<td style="text-align:left">2 days 10 hours 26 minutes 55 seconds 780 msec</td>
<td style="text-align:right">121.8G</td>
<td>618</td>
</tr>
</tbody>
</table>
<p><strong>DefaultCodec</strong>   </p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:left">CPU Time</th>
<th style="text-align:right">输出文件大小</th>
<th>输出文件数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">rcfile</td>
<td style="text-align:left">2 days 10 hours 26 minutes 55 seconds 780 msec</td>
<td style="text-align:right">126.8G</td>
<td>611</td>
</tr>
</tbody>
</table>
<p><strong>关闭压缩</strong>   </p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:left">CPU Time</th>
<th style="text-align:right">输出文件大小</th>
<th>输出文件数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">rcfile</td>
<td style="text-align:left"></td>
<td style="text-align:right">850G</td>
<td>2828</td>
</tr>
</tbody>
</table>
<h2 id="3-__u7EFC_u4E0A_u5B9E_u9A8C_u7ED3_u8BBA"><a href="#3-__u7EFC_u4E0A_u5B9E_u9A8C_u7ED3_u8BBA" class="headerlink" title="3. 综上实验结论"></a>3. 综上实验结论</h2><p>设置上述压缩参数hive表文件格式和压缩编码采用Rcfile+Gzip压缩效果最好，比sequencefile节省约33%存储，而且rcfile 在列筛选数据查询效率上比sequencefile高很多（网上同胞测试过）</p>
<p>综上建议hive默认参数调整如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">set</span> mapred.<span class="keyword">output</span>.compression.<span class="keyword">type</span>=<span class="keyword">BLOCK</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.mapredfiles = <span class="literal">true</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.mapfiles = <span class="literal">true</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.<span class="keyword">merge</span>.smallfiles.avgsize=<span class="number">160000000</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">set</span> hive.exec.<span class="keyword">compress</span>.<span class="keyword">output</span>=<span class="literal">true</span>;</span></span><br></pre></td></tr></table></figure>
<p>hive表文件格式选择：</p>
<p>除了etl表其余表建表默认格式为RCFile</p>
<p>对于已经创建的表用<code>ALTER TABLE table_name SET RCFile;</code>修改后续数据的存储格式，这个设置不影响该表之前存储的数据，因为hive在数据读取的时候预判的文件格式。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/06/27/一些感悟－2016-6-27/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          一些感悟－2016.6.27
        
      </div>
    </a>
  
  
    <a href="/2016/03/28/Tom-Khabaza挖掘9律/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Tom Khabaza挖掘9律</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
    <!-- JiaThis Button BEGIN -->
    <div class="jiathis_style_24x24">
    	<a class="jiathis_button_qzone"></a>
    	<a class="jiathis_button_tsina"></a>
    	<a class="jiathis_button_tqq"></a>
    	<a class="jiathis_button_weixin"></a>
    	<a class="jiathis_button_renren"></a>
    	<a href="http://www.jiathis.com/share?uid=2104974" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
    	<a class="jiathis_counter_style"></a>
    </div>
    <script type="text/javascript">
    var jiathis_config = {data_track_clickback:'true'};
    </script>
    <script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=2104974" charset="utf-8"></script>
    <!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Hive小文件合并原理和技巧" data-title="Hive小文件合并原理和技巧" data-url="http://pengyq.org/2016/04/08/Hive小文件合并原理和技巧/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"pengyq"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		 Box
    	</div>
      	<div class="footer-right">
          Copyright &copy; 2016 [<a href="http://pengyq.org/" target="_blank">pengyq.org</a>]  Powered By pengyq
        <!--
        	<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	-->
        </div>
        
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>